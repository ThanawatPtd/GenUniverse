{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "from azure.storage.blob import generate_blob_sas, BlobSasPermissions, BlobServiceClient\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure environment variables  \n",
    "load_dotenv(find_dotenv('credential.env'), override=True)\n",
    "\n",
    "#Azure storage account credentials\n",
    "connection_string = os.environ['AZURE_BLOB_STORAGE_CONNECTION_STRING']\n",
    "account_name =  os.environ['AZURE_BLOB_STORAGE_ACCOUNT_NAME']\n",
    "account_key =  os.environ['AZURE_BLOB_STORAGE_KEY']\n",
    "container_name =  os.environ['AZURE_BLOB_CONTAINER_NAME']\n",
    "\n",
    "#Azure Document Intelligence credentials\n",
    "endpoint = os.environ['AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT']\n",
    "key= os.environ['AZURE_DOCUMENT_INTELLIGENCE_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare useful method\n",
    "def check_and_create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        print(f\"The folder '{folder_name}' has been created.\")\n",
    "    else:\n",
    "        print(f\"The folder '{folder_name}' already exists.\")\n",
    "\n",
    "def print_error_message(message, prefix_message='Error: '):\n",
    "    print(f\"\\033[1;31m{prefix_message}\\033[0m{message}\")\n",
    "\n",
    "def print_warning_message(message, prefix_message='Warning: '):\n",
    "    print(f\"\\033[1;33m{prefix_message}\\033[0m{message}\")\n",
    "    \n",
    "def print_success_message(message, prefix_message='Success: '):\n",
    "    print(f\"\\033[1;32m{prefix_message}\\033[0m{message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf_to_blobs():\n",
    "    # Blob connection\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    blob_container = blob_service_client.get_container_client(container_name)\n",
    "    if not blob_container.exists():\n",
    "        blob_container.create_container()\n",
    "    \n",
    "    # Upload pdf file in pdf folder to blobs\n",
    "    file_names = []\n",
    "    for file in Path().glob(\"data/pdf_document/*.pdf\"):\n",
    "        blob_container.upload_blob(file.name, file.read_bytes(), overwrite=True)\n",
    "        file_names.append(file.name)\n",
    "    return file_names\n",
    "\n",
    "def get_blob_sas(account_name, account_key, container_name, blob_name):\n",
    "    sas_blob = generate_blob_sas(account_name=account_name, \n",
    "                                container_name=container_name,\n",
    "                                blob_name=blob_name,\n",
    "                                account_key=account_key,\n",
    "                                permission=BlobSasPermissions(read=True),\n",
    "                                expiry=datetime.now(ZoneInfo('UTC')) + timedelta(hours=1))\n",
    "    return sas_blob\n",
    "\n",
    "def get_pdf_file_names_from_blob(container_name, connection_string):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    file_names = []\n",
    "    blob_list = container_client.list_blobs()\n",
    "\n",
    "    for blob in blob_list:\n",
    "        if blob.name.endswith('.pdf'):\n",
    "            file_names.append(blob.name)\n",
    "    \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m>>>[Step1] \u001b[0mUpload documents to Azure storage account and generate SAS URL\n",
      "\u001b[1;32mSuccess: \u001b[0mproduct-oem-bmw.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-1-racing-4t-10w40.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mford.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-moto.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mchanging-motorbike-engine-oil.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-everyday-protection-20w-50.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-all-in-one-protection-5w-40.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-moto-10w-40.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mwhere-to-buy.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mtips-all-drivers-should-know.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-1.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-1-esp-0w-30.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-all-in-one-protection-5w-30.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mbike-and-scooter.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mtoyota.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mrecommended-for-your-car.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mbike-and-scooter-products.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-moto-scooter-gear-oil.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-all-in-one-protection-0w-20.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mhonda.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0misuzu.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmitsubishi.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-moto-20w-50.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mcar.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0msubaru.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-moto-scooter-10w40.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mchoosing-the-right-oil-for-your-car.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-moto-20w40.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0msuzuki.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mtime-to-add-car-care-to-your-calendar.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-1-turbo-diesel-pickup-5w40.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mbenchmarks-to-change-motorcyle-engine-oils.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mchoose-the-right-engine-oil.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mnissan.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmazda.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mmobil-super-moto-10w30.pdf PDF files uploaded to blob storage thanawat-bootcathon-pdf\n",
      "\u001b[1;32mSuccess: \u001b[0mGenerate SAS URLs for all files in thanawat-bootcathon-pdf blob container\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/benchmarks-to-change-motorcyle-engine-oils.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=MJbzwbGvlnRMXdQCC8mbZAfPeppBuqmYVV70szryNYI%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/bike-and-scooter-products.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=Yzpoyri0x0SkZ/rwuHPjNylX/5BGksZafejKqRgHGOo%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/bike-and-scooter.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=P%2BOKllPdoXJVzEUDbq04Gyk1Mi6jbEC7cAbP0r6Yxmg%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/car.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=sJZdDMlV9ISwHwSGveI9z3ck829Xx7xJhv2T1K0dyec%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/changing-motorbike-engine-oil.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=xrFaq8U7RDFabpUoQUf4fDkA1EmCeuBvOdRWteyX0mY%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/choose-the-right-engine-oil.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=RBVfWOaTSU0H/ltAqT1QZQuQzgR4EgorjzsBPxLplKY%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/choosing-the-right-oil-for-your-car.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=qkSfdAfUbKMnMFVRXfo5eb%2BWm4SY/%2BbGBc116prjDyw%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/ford.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=rYwG24QaB8eetzRVOMkRiXQNQVu9ZdYFzmnNk4r9/vA%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/honda.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=aGlhBaUz7jehTCH33JKb/Uq617PepqYAOfbIfLlgU5k%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/isuzu.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=otPeDnIt%2BP8Q8iPknLW7zcsrkYTVFM0G603OgWnK2GI%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mazda.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=SkQuqeYjARLM9ewUlZdNmK84nLsCEVk00lmeHsgkmAI%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mitsubishi.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=2Q7xvXNivJr5UbpyRXmIXoEwZAMVjaXpSauiudoBEIE%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-1-esp-0w-30.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=U8iaN6Jlt5V/5haMmy7Q4AXF5pttdTv70pZ4%2B7jpOW0%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-1-racing-4t-10w40.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=lzJsys1Hbx6l5uCKX2WLk6kUsjIp4cN1W7fo3zoRJMU%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-1-turbo-diesel-pickup-5w40.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=%2B02w4yy0RT7IWdfQsmVsE4mnjBv/Yne7Rf3%2BSMoagqQ%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-1.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=yjFbi383LSejW8FNjAtxwkHmcUa2vRm1KrU5L54Wg9o%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-all-in-one-protection-0w-20.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=CfESFQy0PDwzanZQoQ%2Ba8xejbIpwmDk8dbY4t1iofvU%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-all-in-one-protection-5w-30.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=l%2B4mhKsWxHh6b5smBxteTY7HcLyJOIbSMfDJJcbWMrQ%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-all-in-one-protection-5w-40.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=Lnva2S32bYBXIOKmHRjr4BYayvabrogtYvCsgI8M3Rs%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-everyday-protection-20w-50.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=LcxBKeZ5XvESQZRvXU6aFzSMTm%2BWfXWAhXCO9JCOF2k%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-moto-10w-40.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=wijnFgdIQSwmD6wbFJ1Eu8uAK%2Bpkd8MIIP8QlaPX4Vo%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-moto-10w30.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=xU4uy8XBhIDX/B8bq5zQjCLHAbppPnyiEycNfozx1qQ%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-moto-20w-50.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=ufJKuDBdDhCw63qbcvGB0D0xCtbOMb9p6sVM4hYf1sk%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-moto-20w40.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=wJ%2BX2d817ipk0MiIbWriNhmPbKUDZUQcUe1hxnoiAQc%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-moto-scooter-10w40.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=WXdBXBXb9MfuQTmjycYornf1eOzpzHUmZedwf9Gfldg%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-moto-scooter-gear-oil.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=yOUfZdGTH%2BvfllYyRUlMP5V5BGEOy5vixZecSGTGy/s%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super-moto.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=uV5cd3d18XXtyMZr%2BtXWRQgH3cGpkAwz6y5npfTE4vY%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/mobil-super.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=nfxWYE3wgg8SwtiSlA7L5BI3SEfrLi%2BAxKN8FfyW3Co%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/nissan.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=qfD6dn%2BMph3e%2Bu1K3VnN8h04Yjld7Wx2u8pfVMt2ki8%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/output1.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=lx%2BB%2BL6%2BIGxGJNRHDoaAqupQlUKwf8a7lRTaJmrpXa0%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/output2.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=wZasUy5UM5BQcHvPQywQ%2BxpdKuzOYGSZNtak4uMVYu4%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/product-oem-bmw.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=ZW57KwaFLN0kbQeQGlarpMCcKMTtArc1fIkoTzuCYDg%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/recommended-for-your-car.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=Xh4j3TpmIovnGudlfSxeCzxtiBObLWA64iRhACx3t/s%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/subaru.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=eTI5R9Bggcx7hd%2BSZt1ZhPhXuJZHRB6j54QfhDdxM7Q%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/suzuki.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=4qSRscad6bDwIb0IBMzA/ffFs85lk3qUGqteaKzH91Y%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/time-to-add-car-care-to-your-calendar.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=D1pLLmwEBfcNdFzFWK1rWzPmUW2/i2mUWfBuLSVsi4E%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/tips-all-drivers-should-know.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=Qo4kXTZr3Nz%2Bat3Ny6mDo2U9hf/ek62iLac4Yb1VWmg%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/toyota.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=V9qWvNGBEcGMIbYVk2qlkR/1dO30cmA8qH55VWmBXsI%3D',\n",
       " 'https://bootcathonthanawatsa.blob.core.windows.net/thanawat-bootcathon-pdf/where-to-buy.pdf?se=2024-07-01T17%3A08%3A51Z&sp=r&sv=2024-05-04&sr=b&sig=g8qkxrWb2BR8hnL/yIaPP%2Bhtbau97SdrHVcotXs3lAE%3D']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_names = []\n",
    "url_list = []\n",
    "\n",
    "print_warning_message(\"Upload documents to Azure storage account and generate SAS URL\", \">>>[Step1] \")\n",
    "\n",
    "#Upload PDF file from local folder \"pdf_document\" folder to Azure storage account\n",
    "local_pdf_file_names = upload_pdf_to_blobs()\n",
    "for pdf in local_pdf_file_names:\n",
    "    print_success_message(f\"{pdf} PDF files uploaded to blob storage {container_name}\")\n",
    "\n",
    "#Get a list of file name in specific blob container in Azure storage account\n",
    "pdf_names = get_pdf_file_names_from_blob(container_name, connection_string)\n",
    "\n",
    "#Generate SAS URLs of pdf files in Azure storage account.\n",
    "for pdf in pdf_names:\n",
    "    blob_sas = get_blob_sas(account_name, account_key, container_name, pdf)\n",
    "    url = 'https://'+account_name+'.blob.core.windows.net/'+container_name+'/'+pdf+'?'+blob_sas\n",
    "    url_list.append(url)\n",
    "\n",
    "#Print URL list with SAS of each PDF document in blob storage\n",
    "print_success_message(\"Generate SAS URLs for all files in \"+container_name+\" blob container\")\n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder 'data/document_intelligence_output' already exists.\n",
      "\u001b[1;33m>>>[Step2] \u001b[0mParsing PDF document using Azure Document Intelligence using prebuilt-read model. Please wait...\n",
      "Processing document: benchmarks-to-change-motorcyle-engine-oils.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: bike-and-scooter-products.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: bike-and-scooter.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: car.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: changing-motorbike-engine-oil.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: choose-the-right-engine-oil.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: choosing-the-right-oil-for-your-car.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: ford.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: honda.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: isuzu.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mazda.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mitsubishi.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-1-esp-0w-30.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-1-racing-4t-10w40.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-1-turbo-diesel-pickup-5w40.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-1.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-all-in-one-protection-0w-20.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-all-in-one-protection-5w-30.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-all-in-one-protection-5w-40.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-everyday-protection-20w-50.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-moto-10w-40.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-moto-10w30.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-moto-20w-50.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-moto-20w40.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-moto-scooter-10w40.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-moto-scooter-gear-oil.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super-moto.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: mobil-super.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: nissan.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: output1.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: output2.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: product-oem-bmw.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: recommended-for-your-car.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: subaru.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: suzuki.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: time-to-add-car-care-to-your-calendar.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: tips-all-drivers-should-know.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: toyota.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n",
      "Processing document: where-to-buy.pdf\n",
      "\u001b[1;32mSuccess!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_id = 'prebuilt-read'\n",
    "api_version = '2023-10-31-preview'\n",
    "\n",
    "# Set the local folder name for document intelligence output\n",
    "folder_name = \"document_intelligence_output\"\n",
    "\n",
    "# Check if the folder exists\n",
    "check_and_create_folder(\"data/document_intelligence_output\")\n",
    "\n",
    "print_warning_message(\"Parsing PDF document using Azure Document Intelligence using \" + model_id + \" model. Please wait...\", \">>>[Step2] \")\n",
    "\n",
    "# for index, url in enumerate(url_list):\n",
    "for index, (name, url) in enumerate(zip(pdf_names, url_list)):\n",
    "    print(f\"Processing document: {name}\")\n",
    "    payload = {\n",
    "        \"urlSource\": url\n",
    "    }\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': key\n",
    "    }\n",
    "\n",
    "    #Send a request to document intelligence endpoint with API keys and version\n",
    "    response = requests.post(url=f\"{endpoint}documentintelligence/documentModels/{model_id}:analyze?api-version={api_version}\", headers=headers, json=payload)\n",
    "    \n",
    "    if not response.ok:\n",
    "        response.raise_for_status()\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "    # Add delay when processing each file to allow time for SDK finish the previous document processing.\n",
    "    for sleep_time in [20, 40, 60, 120, 240, 960]:\n",
    "        response_2 = requests.get(response.headers['Operation-Location'], headers=headers)\n",
    "        rst = response_2.json()\n",
    "\n",
    "        if rst['status'] == 'succeeded':\n",
    "            output_path = Path(f\"data/{folder_name}/{index}.json\")\n",
    "            output_path.write_text(json.dumps(rst, ensure_ascii=False), encoding='utf-8')\n",
    "            print_success_message(\"\", \"Success!\")\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(sleep_time)\n",
    "    else:\n",
    "        print_error_message(\"Failed time out\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SECTION_LENGTH = 1000\n",
    "SENTENCE_SEARCH_LIMIT = 100\n",
    "SECTION_OVERLAP = 100\n",
    "\n",
    "def ensure_utf8(s):\n",
    "    return s.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "\n",
    "#Convert table to HTML format\n",
    "def table_to_html(table):\n",
    "    table_html = \"<table>\"\n",
    "    rows = [sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index) for i in range(table.row_count)]\n",
    "    for row_cells in rows:\n",
    "        table_html += \"<tr>\"\n",
    "        for cell in row_cells:\n",
    "            tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "            cell_spans = \"\"\n",
    "            if cell.column_span > 1: cell_spans += f\" colSpan={cell.column_span}\"\n",
    "            if cell.row_span > 1: cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "            table_html += f\"<{tag}{cell_spans}>{html.escape(cell['content'])}</{tag}>\"\n",
    "        table_html +=\"</tr>\"\n",
    "    table_html += \"</table>\"\n",
    "    return table_html\n",
    "\n",
    "def get_document_text(form_recognizer_results):\n",
    "        offset = 0\n",
    "        page_map = []\n",
    "        for page_num, page in enumerate(form_recognizer_results['pages']):\n",
    "            try:\n",
    "                tables_on_page = [table for table in form_recognizer_results['tables'] if table.bounding_regions[0].page_number == page_num + 1]    \n",
    "            except:\n",
    "                tables_on_page = []\n",
    "\n",
    "            # mark all positions of the table spans in the page\n",
    "            page_offset = page['spans'][0]['offset']\n",
    "            page_length = page['spans'][0]['length']\n",
    "            table_chars = [-1]*page_length\n",
    "            for table_id, table in enumerate(tables_on_page):\n",
    "                for span in table['spans']:\n",
    "                    # replace all table spans with \"table_id\" in table_chars array\n",
    "                    for i in range(span['length']):\n",
    "                        idx = span['offset'] - page_offset + i\n",
    "                        if idx >=0 and idx < page_length:\n",
    "                            table_chars[idx] = table_id\n",
    "\n",
    "            # build page text by replacing charcters in table spans with table html\n",
    "            page_text = \"\"\n",
    "            added_tables = set()\n",
    "            for idx, table_id in enumerate(table_chars):\n",
    "                if table_id == -1:\n",
    "                    page_text += form_recognizer_results['content'][page_offset + idx]\n",
    "                elif not table_id in added_tables:\n",
    "                    page_text += table_to_html(tables_on_page[table_id])\n",
    "                    added_tables.add(table_id)\n",
    "\n",
    "            page_text += \" \"\n",
    "            page_map.append((page_num, offset, page_text))\n",
    "            offset += len(page_text)\n",
    "\n",
    "        return page_map\n",
    "\n",
    "#Break down text according to defined length with overlapping in each chunk\n",
    "def split_text(page_map):\n",
    "    SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n",
    "    WORDS_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n",
    "     \n",
    "\n",
    "    def find_page(offset):\n",
    "        l = len(page_map)\n",
    "        for i in range(l - 1):\n",
    "            if offset >= page_map[i][1] and offset < page_map[i + 1][1]:\n",
    "                return i\n",
    "        return l - 1\n",
    "\n",
    "    all_text = \"\".join(p[2] for p in page_map)\n",
    "    length = len(all_text)\n",
    "    start = 0\n",
    "    end = length\n",
    "    while start + SECTION_OVERLAP < length:\n",
    "        last_word = -1\n",
    "        end = start + MAX_SECTION_LENGTH\n",
    "\n",
    "        if end > length:\n",
    "            end = length\n",
    "        else:\n",
    "            # Try to find the end of the sentence\n",
    "            while end < length and (end - start - MAX_SECTION_LENGTH) < SENTENCE_SEARCH_LIMIT and all_text[end] not in SENTENCE_ENDINGS:\n",
    "                if all_text[end] in WORDS_BREAKS:\n",
    "                    last_word = end\n",
    "                end += 1\n",
    "            if end < length and all_text[end] not in SENTENCE_ENDINGS and last_word > 0:\n",
    "                end = last_word # Fall back to at least keeping a whole word\n",
    "        if end < length:\n",
    "            end += 1\n",
    "\n",
    "        # Try to find the start of the sentence or at least a whole word boundary\n",
    "        last_word = -1\n",
    "        while start > 0 and start > end - MAX_SECTION_LENGTH - 2 * SENTENCE_SEARCH_LIMIT and all_text[start] not in SENTENCE_ENDINGS:\n",
    "            if all_text[start] in WORDS_BREAKS:\n",
    "                last_word = start\n",
    "            start -= 1\n",
    "        if all_text[start] not in SENTENCE_ENDINGS and last_word > 0:\n",
    "            start = last_word\n",
    "        if start > 0:\n",
    "            start += 1\n",
    "\n",
    "        section_text = all_text[start:end]\n",
    "        yield (section_text, find_page(start))\n",
    "\n",
    "        last_table_start = section_text.rfind(\"<table\")\n",
    "        if (last_table_start > 2 * SENTENCE_SEARCH_LIMIT and last_table_start > section_text.rfind(\"</table\")):\n",
    "            # If the section ends with an unclosed table, we need to start the next section with the table.\n",
    "            # If table starts inside SENTENCE_SEARCH_LIMIT, we ignore it, as that will cause an infinite loop for tables longer than MAX_SECTION_LENGTH\n",
    "            # If last table starts inside SECTION_OVERLAP, keep overlapping\n",
    "            \n",
    "            start = min(end - SECTION_OVERLAP, start + last_table_start)\n",
    "        else:\n",
    "            start = end - SECTION_OVERLAP\n",
    "        \n",
    "    if start + SECTION_OVERLAP < end:\n",
    "        yield (all_text[start:end], find_page(start))\n",
    "\n",
    "#Extend the PDF file name with page number\n",
    "def blob_name_from_file_page(filename, page = 0):\n",
    "    if os.path.splitext(filename)[1].lower() == \".pdf\":\n",
    "        return os.path.splitext(os.path.basename(filename))[0] + f\"-{page}\" + \".pdf\"\n",
    "    else:\n",
    "        return os.path.basename(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m>>>[Step3] \u001b[0mBreak down JSON output to mulitple 1000 characters document chunks\n",
      "The folder 'chunked_document' already exists.\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #4 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #2 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #3 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #0 is created in 'chunked_document' folder\u001b[0m\n",
      "\u001b[1;32mChunked document #1 is created in 'chunked_document' folder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print_warning_message(\"Break down JSON output to mulitple \"+str(MAX_SECTION_LENGTH)+\" characters document chunks\", \">>>[Step3] \")\n",
    "\n",
    "# Check if the folder exists\n",
    "check_and_create_folder(\"chunked_document\")\n",
    "\n",
    "for index, file_name in enumerate(pdf_names):\n",
    "    try:\n",
    "        with open(f'data/document_intelligence_output/{str(index)}.json', encoding='utf-8') as JSON:\n",
    "            raw_json = json.load(JSON)\n",
    "    except Exception as e:\n",
    "        print_error_message(f\"Error reading JSON file for {file_name}\", str(e))\n",
    "        continue\n",
    "\n",
    "    page_map = get_document_text(raw_json['analyzeResult'])\n",
    "\n",
    "    for i, (section, pagenum) in enumerate(split_text(page_map)):\n",
    "        try:\n",
    "            doc = {\n",
    "                \"id\": re.sub(\"[^0-9a-zA-Z_-]\", \"_\", f\"{file_name}-{i}\"),\n",
    "                \"content\": ensure_utf8(section),\n",
    "                \"category\": 'Not Available',\n",
    "                \"sourcepage\": blob_name_from_file_page(file_name, pagenum),\n",
    "                \"sourcefile\": file_name\n",
    "            }\n",
    "            with open(f'data/chunked_document/{doc[\"id\"]}.json', 'w', encoding='utf-8') as file:\n",
    "                json.dump(doc, file, ensure_ascii=False)\n",
    "            print_success_message(\"\", f\"Chunked document #{i} is created in 'chunked_document' folder\")\n",
    "        except Exception as error:\n",
    "            print_error_message(f\"Error on '{file_name}' | chunk#{i}\", str(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
